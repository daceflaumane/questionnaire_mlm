{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4eb7440-6986-4cdf-af23-decc4e5f7e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /opt/conda/lib/python3.11/site-packages (3.0.1)\n",
      "Requirement already satisfied: utils in /opt/conda/lib/python3.11/site-packages (1.0.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: openpyxl in /opt/conda/lib/python3.11/site-packages (3.1.5)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (4.42.4)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (2.3.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (1.5.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (0.24.0)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: et-xmlfile in /opt/conda/lib/python3.11/site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.5.15)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U sentence-transformers utils pandas openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d13746c-11f9-4ff2-8183-d56540dcbeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7bab567b-5c32-4783-ad58-ee9977863615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Question': 'What is cybersecurity?', 'Answer': 'Cybersecurity is the practice of protecting systems, networks, and programs from digital attacks.'}, {'Question': 'Why is cybersecurity important?', 'Answer': 'Cybersecurity is important because it protects sensitive data from unauthorized access and cyber threats.'}, {'Question': 'What are the common types of cyber threats?', 'Answer': 'Common types of cyber threats include malware, phishing, ransomware, and denial-of-service (DoS) attacks.'}, {'Question': 'What is a firewall?', 'Answer': 'A firewall is a network security device that monitors and filters incoming and outgoing network traffic based on security rules.'}, {'Question': 'What is phishing?', 'Answer': 'Phishing is a type of cyber attack where attackers pose as legitimate entities to steal sensitive information such as login credentials.'}, {'Question': 'What is malware?', 'Answer': 'Malware is malicious software designed to disrupt, damage, or gain unauthorized access to computer systems.'}, {'Question': 'What are the best practices for password management?', 'Answer': 'Best practices for password management include using strong passwords, changing them regularly, and using a password manager.'}, {'Question': 'What is encryption?', 'Answer': 'Encryption is the process of converting data into a coded format to prevent unauthorized access.'}, {'Question': 'What is a VPN?', 'Answer': 'A VPN (Virtual Private Network) provides a secure connection to another network over the internet, protecting your online activities from spying and interference.'}, {'Question': 'How can you protect against ransomware?', 'Answer': 'To protect against ransomware, regularly back up data, use antivirus software, and avoid clicking on suspicious links or attachments.'}]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_excel(r\"cybersecurity_questions_answers.xlsx\")\n",
    "question_answers = df.to_dict(orient='records')\n",
    "\n",
    "print(question_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46fe1bb9-3879-46f9-a754-e46438c427be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Question': 'What is cybersecurity?', 'Answer': nan}, {'Question': 'Why is cybersecurity important?', 'Answer': nan}, {'Question': 'What are the common types of cyber threats?', 'Answer': nan}, {'Question': 'What is a firewall?', 'Answer': nan}, {'Question': 'What is phishing?', 'Answer': nan}, {'Question': 'What is malware?', 'Answer': nan}, {'Question': 'What are the best practices for password management?', 'Answer': nan}, {'Question': 'What is encryption?', 'Answer': nan}, {'Question': 'What is a VPN?', 'Answer': nan}, {'Question': 'How can you protect against ransomware?', 'Answer': nan}]\n"
     ]
    }
   ],
   "source": [
    "qu = pd.read_excel(\"questions.xlsx\") \n",
    "questions_to_answer = qu.to_dict(orient='records')\n",
    "print(questions_to_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "144745ab-b449-4a4e-8884-8f02845ee113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0]  # First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fa256e40-19f6-445a-9f70-d35cf3412103",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Extract sentences from the question_answers\n",
    "sentences = [item['Question'] for item in question_answers]\n",
    "\n",
    "# Tokenize sentences\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "# Perform pooling\n",
    "question_answer_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "# Normalize embeddings\n",
    "question_answer_embeddings = F.normalize(question_answer_embeddings, p=2, dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "58f704a2-b533-4a7b-a4c0-24721e767e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0299,  0.0093, -0.1318,  ..., -0.0320,  0.0615, -0.0100],\n",
      "        [ 0.0170,  0.0260, -0.0422,  ..., -0.0312,  0.0258, -0.0510],\n",
      "        [ 0.0315, -0.0462, -0.0111,  ..., -0.0403,  0.0151,  0.0470],\n",
      "        ...,\n",
      "        [-0.0396,  0.0358, -0.0932,  ...,  0.0762,  0.0708, -0.0731],\n",
      "        [-0.0997,  0.0071, -0.0198,  ..., -0.0067,  0.0482,  0.0020],\n",
      "        [-0.1075,  0.1236, -0.0403,  ..., -0.0833,  0.0895,  0.0155]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Extract input sentences for tokenization\n",
    "input_questions = [row[\"Question\"] for row in questions_to_answer]\n",
    "\n",
    "# Tokenize sentences\n",
    "encoded_questions = tokenizer(input_questions, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    questions_model_output = model(**encoded_questions)\n",
    "\n",
    "# Perform pooling\n",
    "question_embeddings = mean_pooling(questions_model_output, encoded_questions['attention_mask'])\n",
    "\n",
    "# Normalize embeddings\n",
    "question_embeddings = F.normalize(question_embeddings, p=2, dim=1)\n",
    "\n",
    "print(question_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7b639bd4-5f13-41c2-b5a4-20645d172b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_filled = []\n",
    "questions_filled_similarity_scores = []\n",
    "\n",
    "for idx, question_embedding in enumerate(question_embeddings):\n",
    "    similarity_scores = {}\n",
    "    for idx, question_answer_embedding in enumerate(question_answer_embeddings):\n",
    "        similarity = pytorch_cos_sim(question_embedding, question_answer_embedding)\n",
    "        similarity_scores[idx] = similarity.item()\n",
    "\n",
    "    # sorted_similarity_scores = dict(sorted(similarity_scores.items(), key=lambda item: item[1]))\n",
    "    sorted_similarity_scores = dict(sorted(similarity_scores.items(), key=lambda item: item[1], reverse=True))\n",
    "    first_key = next(iter(sorted_similarity_scores))\n",
    "    questions_filled.append(question_answers[first_key]['Answer'])\n",
    "    questions_filled_similarity_scores.append(round(sorted_similarity_scores[first_key],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ca7c7f8e-c334-4842-a9c1-bd7d6c9d3a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame is written to Excel File successfully.\n"
     ]
    }
   ],
   "source": [
    "# importing the module\n",
    "import pandas as pd\n",
    "\n",
    "# creating the DataFrame\n",
    "questions_with_answers_export = pd.DataFrame({\n",
    "    'Question': input_questions,\n",
    "    'Similiarity': questions_filled_similarity_scores,\n",
    "    'Answer': questions_filled,\n",
    "})\n",
    "\n",
    "# determining the name of the file\n",
    "file_name = 'questions_filled.xlsx'\n",
    "\n",
    "# saving the excel\n",
    "questions_with_answers_export.to_excel(file_name)\n",
    "print('DataFrame is written to Excel File successfully.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bed278-cb3a-4a02-a605-a9658bb8839e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
